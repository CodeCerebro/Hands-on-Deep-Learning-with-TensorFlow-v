{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Imported dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cancer_data = load_breast_cancer()\n",
    "m, n = cancer_data.data.shape\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Training Dataset\n",
    "train_data =  cancer_data.data[0:400]\n",
    "scaled_training_cancer_data = scaler.fit_transform(train_data)\n",
    "training_cancer_data = cancer_data.target[0:400]\n",
    "\n",
    "# Validation Dataset\n",
    "validation_data =  cancer_data.data[400:500]\n",
    "scaled_validation_cancer_data = scaler.fit_transform(validation_data)\n",
    "validation_cancer_data = cancer_data.target[400:500]\n",
    "\n",
    "# Testing Dataset\n",
    "testing_data =  cancer_data.data[500:569]\n",
    "scaled_testing_cancer_data = scaler.fit_transform(testing_data)\n",
    "testing_cancer_data = cancer_data.target[500:569]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Layers of Neural Network in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected, dropout\n",
    "\n",
    "# No. of neurons Initialization\n",
    "n_inputs = n\n",
    "n_hidden1 = 46\n",
    "n_hidden2 = 30\n",
    "n_outputs = 2\n",
    "\n",
    "# Placeholders to hold the data\n",
    "X = tf.placeholder(tf.float32, shape = (None, n_inputs), name = \"X\")\n",
    "y = tf.placeholder(tf.int32, shape = (None), name = \"y\")\n",
    "\n",
    "# Weights Initializer\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "is_training = tf.placeholder(dtype = tf.bool, shape = (), name = \"is_training\")\n",
    "\n",
    "# Adding a dropout layer\n",
    "keep_prob = 0.5\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    X_drop = dropout(X, keep_prob, is_training= is_training)\n",
    "    \n",
    "    hidden1 = fully_connected(X_drop, n_hidden1,\n",
    "                             weights_initializer = he_init,\n",
    "                             activation_fn = tf.nn.elu,\n",
    "                             scope = \"hidden1\")\n",
    "\n",
    "    hidden1_drop = dropout(hidden1, keep_prob, is_training= is_training)\n",
    "    \n",
    "    hidden2 = fully_connected(hidden1_drop, n_hidden2,\n",
    "                             weights_initializer = he_init,\n",
    "                             activation_fn = tf.nn.elu,\n",
    "                             scope = \"hidden2\")\n",
    "    \n",
    "    hidden2_drop = dropout(hidden2, keep_prob, is_training= is_training)\n",
    "    \n",
    "    logits = fully_connected(hidden2_drop, n_hidden2,\n",
    "                             weights_initializer = he_init,\n",
    "                             activation_fn = tf.nn.elu,\n",
    "                             scope = \"outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing the Linear Regression Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits = logits)\n",
    "    loss = tf.reduce_mean(xentropy, name = \"loss\")\n",
    "    \n",
    "lr = 0.01\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Creating directory name\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_dir = \"tf_logs/\"\n",
    "logdir = \"{}/run{}\".format(root_dir, now)\n",
    "\n",
    "# Information to create logs\n",
    "mse_summary = tf.summary.scalar(\"LOSS\", loss)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying built Neural Network for Predicting whether  people in Wisconsin State having Breast Cancer is Benign or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy 0.0025 Validation accuracy 0.01\n",
      "1 Train accuracy 0.065 Validation accuracy 0.06\n",
      "2 Train accuracy 0.39 Validation accuracy 0.29\n",
      "3 Train accuracy 0.6675 Validation accuracy 0.53\n",
      "4 Train accuracy 0.7725 Validation accuracy 0.69\n",
      "5 Train accuracy 0.8425 Validation accuracy 0.8\n",
      "6 Train accuracy 0.885 Validation accuracy 0.88\n",
      "7 Train accuracy 0.9225 Validation accuracy 0.89\n",
      "8 Train accuracy 0.9275 Validation accuracy 0.91\n",
      "9 Train accuracy 0.93 Validation accuracy 0.91\n",
      "10 Train accuracy 0.93 Validation accuracy 0.91\n",
      "11 Train accuracy 0.9375 Validation accuracy 0.92\n",
      "12 Train accuracy 0.94 Validation accuracy 0.92\n",
      "13 Train accuracy 0.9425 Validation accuracy 0.92\n",
      "14 Train accuracy 0.945 Validation accuracy 0.92\n",
      "15 Train accuracy 0.9475 Validation accuracy 0.92\n",
      "16 Train accuracy 0.955 Validation accuracy 0.91\n",
      "17 Train accuracy 0.955 Validation accuracy 0.9\n",
      "18 Train accuracy 0.9575 Validation accuracy 0.9\n",
      "19 Train accuracy 0.96 Validation accuracy 0.9\n",
      "20 Train accuracy 0.9625 Validation accuracy 0.91\n",
      "21 Train accuracy 0.965 Validation accuracy 0.91\n",
      "22 Train accuracy 0.9675 Validation accuracy 0.91\n",
      "23 Train accuracy 0.97 Validation accuracy 0.92\n",
      "24 Train accuracy 0.9725 Validation accuracy 0.92\n",
      "25 Train accuracy 0.97 Validation accuracy 0.92\n",
      "26 Train accuracy 0.97 Validation accuracy 0.93\n",
      "27 Train accuracy 0.97 Validation accuracy 0.93\n",
      "28 Train accuracy 0.9725 Validation accuracy 0.93\n",
      "29 Train accuracy 0.975 Validation accuracy 0.92\n",
      "30 Train accuracy 0.98 Validation accuracy 0.93\n",
      "31 Train accuracy 0.98 Validation accuracy 0.92\n",
      "32 Train accuracy 0.9825 Validation accuracy 0.91\n",
      "33 Train accuracy 0.9825 Validation accuracy 0.91\n",
      "34 Train accuracy 0.9825 Validation accuracy 0.91\n",
      "35 Train accuracy 0.985 Validation accuracy 0.91\n",
      "36 Train accuracy 0.985 Validation accuracy 0.91\n",
      "37 Train accuracy 0.98 Validation accuracy 0.9\n",
      "38 Train accuracy 0.98 Validation accuracy 0.89\n",
      "39 Train accuracy 0.98 Validation accuracy 0.89\n",
      "40 Train accuracy 0.98 Validation accuracy 0.89\n",
      "41 Train accuracy 0.98 Validation accuracy 0.89\n",
      "42 Train accuracy 0.98 Validation accuracy 0.89\n",
      "43 Train accuracy 0.98 Validation accuracy 0.89\n",
      "44 Train accuracy 0.98 Validation accuracy 0.89\n",
      "45 Train accuracy 0.98 Validation accuracy 0.89\n",
      "46 Train accuracy 0.98 Validation accuracy 0.89\n",
      "47 Train accuracy 0.98 Validation accuracy 0.89\n",
      "48 Train accuracy 0.98 Validation accuracy 0.89\n",
      "49 Train accuracy 0.98 Validation accuracy 0.89\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op, feed_dict = {X : scaled_training_cancer_data, y:training_cancer_data, is_training : True})\n",
    "        acc_train = accuracy.eval(feed_dict={X : scaled_training_cancer_data, y:training_cancer_data, is_training : False})\n",
    "        acc_validation = accuracy.eval(feed_dict={X : scaled_validation_cancer_data, y:validation_cancer_data, is_training : False})\n",
    "        summary_str = mse_summary.eval(feed_dict = {X : scaled_training_cancer_data, y:training_cancer_data, is_training : False}) \n",
    "        file_writer.add_summary(summary_str, epoch)\n",
    "        print(epoch, \"Train accuracy\", acc_train, \"Validation accuracy\", acc_validation)\n",
    "    save_path = saver.save(sess, \"./my_model_find.ckpt\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_find.ckpt\n",
      "Testing accuracy 0.9130435\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_find.ckpt\")\n",
    "    acc_testing = accuracy.eval(feed_dict={X : scaled_testing_cancer_data, y:testing_cancer_data, is_training : False})\n",
    "    print(\"Testing accuracy\", acc_testing)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
