{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load GPS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from gmplot import gmplot\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def readData(pth):\n",
    "    # Read all the files\n",
    "    path = pth # use your path\n",
    "    allFiles = glob.glob(path+ \"/*plt\")\n",
    "    frame = pd.DataFrame()\n",
    "    list_ = []\n",
    "    for file_ in allFiles:\n",
    "        df = pd.read_csv(file_, skiprows =  6, header = None)\n",
    "        list_.append(df)\n",
    "    df = pd.concat(list_)\n",
    "    df = df[[0,1]]\n",
    "    df.columns = ['Latitude', 'Longitude']\n",
    "    return(df)\n",
    "\n",
    "def plotData(dframe):\n",
    "    # Using Google maps aplot and save the html file\n",
    "    gmap = gmplot.GoogleMapPlotter.from_geocode(\"Beijing\")\n",
    "    gmap.plot(dframe['Latitude'], dframe['Longitude'], 'cornflowerblue', edge_width = 10)\n",
    "    gmap.draw(\"my_map.html\")\n",
    "    \n",
    "df = readData(r'/home/kulwant/Documents/Packt_Course/Generative Adversarial Networks/Geolife Trajectories 1.3/Data/001/Trajectory/')  # <= Pass here your path\n",
    "plotData(df)\n",
    "data = np.array(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Generator and Discriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_hidden = 50\n",
    "\n",
    "def generator(X, reuse =False):\n",
    "    with tf.variable_scope('GAN/Generator',  reuse = reuse):\n",
    "        hidden1 = tf.layers.dense(X, n_hidden, activation = tf.nn.leaky_relu)\n",
    "        hidden2 = tf.layers.dense(hidden1, n_hidden, activation = tf.nn.leaky_relu)\n",
    "        output = tf.layers.dense(hidden2, 2)\n",
    "    return(output)\n",
    "\n",
    "def discriminator(X, reuse = False):\n",
    "    with tf.variable_scope('GAN/Discriminator', reuse = reuse):\n",
    "        hidden1 = tf.layers.dense(X, n_hidden, activation = tf.nn.leaky_relu)\n",
    "        hidden2 = tf.layers.dense(hidden1, n_hidden, activation = tf.nn.leaky_relu)\n",
    "        hidden3 = tf.layers.dense(hidden2, 2)\n",
    "        output = tf.layers.dense(hidden3, 1)\n",
    "    return(hidden3, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function Computation and it's Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R is our real data placeholder\n",
    "R = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "# F is our fake data placeholder\n",
    "F = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "# Calling the generator and Discriminator\n",
    "genData = generator(F, reuse = False)\n",
    "rLogits, rPrb = discriminator(R, reuse = False)\n",
    "fLogits, gPrb = discriminator(genData, reuse = True)\n",
    "\n",
    "# Loss Calculation\n",
    "# fake images === 1 (Generator Loss)\n",
    "genLoss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = fLogits, labels = tf.ones_like(fLogits)))\n",
    "\n",
    "\n",
    "\n",
    "# fake images === 0 and real images === 1\n",
    "discLoss  = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = fLogits, labels = tf.zeros_like(fLogits))\n",
    "                        +\n",
    "                         tf.nn.sigmoid_cross_entropy_with_logits(logits = rLogits, labels = tf.ones_like(rLogits))\n",
    "                        )\n",
    "\n",
    "\n",
    "# variable scope variables\n",
    "genScope = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = 'GAN/Generator')\n",
    "discScope = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = 'GAN/Discriminator')\n",
    "\n",
    "                              \n",
    "#Create a method for creating a optimization method\n",
    "genOpt = tf.train.RMSPropOptimizer(learning_rate= 0.001).minimize(genLoss, var_list = genScope) # G Train Step\n",
    "discOpt = tf.train.RMSPropOptimizer(learning_rate= 0.001).minimize(discLoss, var_list = discScope) # G Train Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 0\t Discriminator loss: 0.7200\t Generator loss: 0.6928\n",
      "Iterations: 1\t Discriminator loss: 0.6965\t Generator loss: 0.6978\n",
      "Iterations: 2\t Discriminator loss: 0.6855\t Generator loss: 0.7052\n",
      "Iterations: 3\t Discriminator loss: 0.6738\t Generator loss: 0.7159\n",
      "Iterations: 4\t Discriminator loss: 0.6587\t Generator loss: 0.7317\n"
     ]
    }
   ],
   "source": [
    "def randomData(m, n):\n",
    "    return np.random.uniform(-1., 1., size = [m, n])\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "batch_size = 108607\n",
    "dItr = 10\n",
    "gItr = 10\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for i in range(2000):\n",
    "        X_batch = data\n",
    "        Z_batch = randomData(batch_size, 2)\n",
    "        \n",
    "        # Here we do 2 things \n",
    "        # Discriminator loss and optimize it \n",
    "        for _ in range(dItr):\n",
    "            _, dloss = sess.run([discOpt, discLoss], feed_dict = {R: X_batch, F:Z_batch})\n",
    "        _, _ = sess.run([rPrb, gPrb], feed_dict = {R: X_batch, F:Z_batch})\n",
    "        \n",
    "        # Here we do 2 things \n",
    "        # Generator loss and optimize it \n",
    "        for _ in range(dItr):\n",
    "            _, gloss = sess.run([genOpt, genLoss], feed_dict = {F:Z_batch})\n",
    "        _, _ = sess.run([rPrb, gPrb], feed_dict = {R: X_batch, F:Z_batch})\n",
    "        \n",
    "        print(\"Iterations: %d\\t Discriminator loss: %.4f\\t Generator loss: %.4f\"%(i, dloss, gloss))\n",
    "    saver.save(sess, \"./my_model_all_layers.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plot = data\n",
    "Z_batch = randomData(len(data), 2)\n",
    "plt.figure()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_all_layers.ckpt\")\n",
    "    g_plot = sess.run(generator(F, True), feed_dict = {F: Z_batch})\n",
    "xax = plt.scatter(x_plot[:,0], x_plot[:, 1])\n",
    "gax = plt.scatter(g_plot[:,0], g_plot[:, 1])\n",
    "\n",
    "plt.legend((xax, gax), (\"Real Data\", \"Generated Data\"))\n",
    "plt.title('Real Vs Synthetic Data')\n",
    "plt.tight_layout()\n",
    "plt.savefig('Results_Comparison.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(a, b= True):\n",
    "    b =b\n",
    "    print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(6, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
